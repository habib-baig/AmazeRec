{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.factorization import explicit, implicit\n",
    "from spotlight.evaluation import mrr_score, rmse_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = pd.read_pickle('../reviews_Sports_and_Outdoors_5.h5')\n",
    "df.to_csv('../reviews_Sports_and_Outdoors_5.csv')\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lists of unique movies and users\n",
    "movie_list = list(set(df['asin'].values))\n",
    "user_list = list(set(df['reviewerID'].values))\n",
    "\n",
    "#Storing the indices of users to generate the Rating Memory Matrix\n",
    "UserIndices={}\n",
    "for i in range(len(user_list)):\n",
    "    UserIndices[user_list[i]] = i\n",
    "\n",
    "#Storing the indices of movies to generate the Rating Memory Matrix\n",
    "#These indices will be used to populate the UsersRatingMemory for Memory based Collaborative Filtering\n",
    "MovieIndices={}\n",
    "for j in range(len(movie_list)):\n",
    "    MovieIndices[movie_list[j]] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids=[]\n",
    "item_ids=[]\n",
    "ratings=[]\n",
    "for i in range(0, len(df)):\n",
    "    item_id=df.iloc[i]['asin']\n",
    "    user_id=df.iloc[i]['reviewerID']\n",
    "    user_ind=UserIndices[user_id]\n",
    "    item_ind=MovieIndices[item_id]\n",
    "    user_ids.append(user_ind)\n",
    "    item_ids.append(item_ind)\n",
    "    ratings.append(float(df.iloc[i]['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.interactions import Interactions\n",
    "user_ids_list=np.array(user_ids,dtype=np.int32)\n",
    "item_ids_list=np.array(item_ids,dtype=np.int32)\n",
    "ratings_list=np.array(ratings,dtype=np.float32)\n",
    "dataset = Interactions(user_ids_list, item_ids_list,ratings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "LATENT_DIM = 32\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "L2 = 1e-6\n",
    "LEARNING_RATE = 1e-3\n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "explicit_model = explicit.ExplicitFactorizationModel(loss='regression',\n",
    "                                                     embedding_dim=LATENT_DIM,\n",
    "                                                     n_iter=NUM_EPOCHS,\n",
    "                                                     learning_rate=LEARNING_RATE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     l2=L2,\n",
    "                                                     random_state=np.random.RandomState(RANDOM_SEED))\n",
    "implicit_model = implicit.ImplicitFactorizationModel(loss='bpr',\n",
    "                                                     embedding_dim=LATENT_DIM,\n",
    "                                                     n_iter=NUM_EPOCHS,\n",
    "                                                     learning_rate=LEARNING_RATE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     l2=L2,\n",
    "                                                     random_state=np.random.RandomState(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "implicit_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implicit MRR: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('Implicit MRR: {:.2f}'.format(mrr_score(implicit_model, test, train=train).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explicit_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implicit MRR: 0.01\n"
     ]
    }
   ],
   "source": [
    "print('Implicit MRR: {:.2f}'.format(mrr_score(explicit_model, test, train=train).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
