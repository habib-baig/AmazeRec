{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('../reviews_Books_5.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df.to_pickle('reviews_Books_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin     reviewerName helpful  unixReviewTime  \\\n",
      "0    AIXZKN4ACSKI  1881509818     David Briner  [0, 0]      1390694400   \n",
      "1  A1L5P841VIO02V  1881509818  Jason A. Kramer  [1, 1]      1328140800   \n",
      "\n",
      "                                          reviewText  overall   reviewTime  \\\n",
      "0  This came in on time and I am veru happy with ...      5.0  01 26, 2014   \n",
      "1  I had a factory Glock tool that I was using fo...      5.0   02 2, 2012   \n",
      "\n",
      "                             summary  \n",
      "0                     Woks very good  \n",
      "1  Works as well as the factory tool  \n"
     ]
    }
   ],
   "source": [
    "print df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = pd.read_pickle('reviews_Books_5.h5')\n",
    "df.to_csv('reviews_Books_5.csv')\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Training_DataFrame, Testing_DataFrame = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237069, 9)\n",
      "(59268, 9)\n"
     ]
    }
   ],
   "source": [
    "print Training_DataFrame.shape\n",
    "print Testing_DataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset details:\n",
      "Number of item: 18356\n",
      "Number of Users: 35589\n",
      "Number of ratings: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training dataset details:\"\n",
    "Uniq_movies_Train =  len(set(Training_DataFrame['asin'].values))\n",
    "print \"Number of item:\", Uniq_movies_Train\n",
    "Uniq_users_Train =   len(set(Training_DataFrame['reviewerID'].values))\n",
    "print \"Number of Users:\", Uniq_users_Train\n",
    "Uniq_ratings_Train = len(set(Training_DataFrame['overall'].values))\n",
    "print \"Number of ratings:\", Uniq_ratings_Train\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            reviewerID        asin reviewerName helpful  unixReviewTime  \\\n",
      "209248   A99N6WDOKAFFA  B0049ZFP7U     Goldencr  [1, 1]      1360195200   \n",
      "181919  A2D0CO1OA6DSWY  B0038ZYRGC          Gil  [0, 0]      1360195200   \n",
      "\n",
      "                                               reviewText  overall  \\\n",
      "209248  The description says for 26 but it works great...      4.0   \n",
      "181919  I have these on for hours, they are comfortabl...      4.0   \n",
      "\n",
      "        reviewTime            summary  \n",
      "209248  02 7, 2013  Great Fit on 29er  \n",
      "181919  02 7, 2013      Why pay more?  \n",
      "Average Ratings of the Users are:\n",
      "[4.16666667 4.25       4.8        ... 4.11764706 4.8        2.33333333]\n"
     ]
    }
   ],
   "source": [
    "#Training_DataFrame=Training_DataFrame[:5000]\n",
    "Training_DataFrame.columns\n",
    "# Lists of unique movies and users\n",
    "movie_list = list(set(Training_DataFrame['asin'].values))\n",
    "user_list = list(set(Training_DataFrame['reviewerID'].values))\n",
    "\n",
    "print Training_DataFrame[0:2]\n",
    "#Storing the indices of users to generate the Rating Memory Matrix\n",
    "UserIndices={}\n",
    "for i in range(len(user_list)):\n",
    "    UserIndices[user_list[i]] = i\n",
    "\n",
    "#Storing the indices of movies to generate the Rating Memory Matrix\n",
    "#These indices will be used to populate the UsersRatingMemory for Memory based Collaborative Filtering\n",
    "MovieIndices={}\n",
    "for j in range(len(movie_list)):\n",
    "    MovieIndices[movie_list[j]] = j\n",
    "    \n",
    "#UsersRatingMemory stores the users and corresponding movies ratings in Matrix form\n",
    "UsersRatingMemory=np.zeros((Uniq_users_Train,Uniq_movies_Train))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    movie_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and movie indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    movie_ind=MovieIndices[movie_id]\n",
    "    rating=Training_DataFrame.iloc[i]['overall']\n",
    "    #populate the matrix with rating at corresponding user and movie index\n",
    "    UsersRatingMemory[user_ind][movie_ind]=float(rating)\n",
    "\n",
    "AvgRatings = np.true_divide(UsersRatingMemory.sum(1),(UsersRatingMemory!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "def PredictUserRating(user_id, movie_id):\n",
    "    '''This function predicts the rating based on user_id and movie_id'''\n",
    "    movie_ind = MovieIndices[movie_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the movie\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory[:,movie_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #MovieRatingsOthers: stores other users ratings\n",
    "    MovieRatingsOthers = UsersRatingMemory[ratedindices, movie_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory[ind],UsersRatingMemory[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRatings[user_ind] + k * np.sum( PearsonCoeffs* (MovieRatingsOthers - AvgRatings[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Test(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        movie_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRating(user_id,movie_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'reviewerID', u'asin', u'reviewerName', u'helpful', u'unixReviewTime',\n",
      "       u'reviewText', u'overall', u'reviewTime', u'summary'],\n",
      "      dtype='object')\n",
      "For 10 Samples:\n",
      "The Mean Absolute Error is: 0.6741605049396879\n",
      "Root Mean Square Error is: 0.9926953965814299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print Testing_DataFrame.columns\n",
    "Predictions=Test(1000)\n",
    "print \"For 10 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'].values[:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating = [mem for mem in UsersRatingMemory[:][1] if mem ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 3.0, 5.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "print rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings of the Users are:\n",
      "[4.68426667 4.33795    5.39975    ... 4.97775882 5.5613     2.6225    ]\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sent = SentimentIntensityAnalyzer()\n",
    "UsersRatingMemory_sentiment=np.zeros((Uniq_users_Train,Uniq_movies_Train))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    movie_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and movie indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    movie_ind=MovieIndices[movie_id]\n",
    "    rating=float(Training_DataFrame.iloc[i]['overall'])\n",
    "    \n",
    "    if Training_DataFrame.iloc[i]['reviewText']:\n",
    "    #populate the matrix with rating at corresponding user and movie index\n",
    "        sentiment_rating=sent.polarity_scores(Training_DataFrame.iloc[i]['reviewText'])['compound']\n",
    "        rating=sentiment_rating+rating\n",
    "    \n",
    "    UsersRatingMemory_sentiment[user_ind][movie_ind]=rating\n",
    "\n",
    "AvgRatings = np.true_divide(UsersRatingMemory_sentiment.sum(1),(UsersRatingMemory_sentiment!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PredictUserRatingsentiment(user_id, movie_id):\n",
    "    '''This function predicts the rating based on user_id and movie_id'''\n",
    "    movie_ind = MovieIndices[movie_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the movie\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory_sentiment[:,movie_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #MovieRatingsOthers: stores other users ratings\n",
    "    MovieRatingsOthers = UsersRatingMemory_sentiment[ratedindices, movie_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory_sentiment[ind],UsersRatingMemory_sentiment[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRatings[user_ind] + k * np.sum( PearsonCoeffs* (MovieRatingsOthers - AvgRatings[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Test(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        movie_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRatingsentiment(user_id,movie_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'reviewerID', u'asin', u'reviewerName', u'helpful', u'unixReviewTime',\n",
      "       u'reviewText', u'overall', u'reviewTime', u'summary'],\n",
      "      dtype='object')\n",
      "For 10 Samples:\n",
      "The Mean Absolute Error is: 0.8428040351856583\n",
      "Root Mean Square Error is: 1.190641797190995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print Testing_DataFrame.columns\n",
    "Predictions=Test(1000)\n",
    "print \"For 10 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'][:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UsersRatingMemory_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-861bba8ef200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUsersRatingMemory_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUsersRatingMemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'UsersRatingMemory_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "m = [mem for mem in UsersRatingMemory_sentiment[:][1] if mem ]\n",
    "print m\n",
    "m = [mem for mem in UsersRatingMemory[:][1] if mem ]\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
