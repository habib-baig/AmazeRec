{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_extracted=True\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "if already_extracted:\n",
    "    df = pd.read_pickle('../reviews_Kindle_Store_5.h5')\n",
    "else:\n",
    "    df = getDF('../reviews_Kindle_Store_5.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(982619, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#df.to_csv('reviews_Books_5.csv')\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Training_DataFrame, Testing_DataFrame = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            reviewerID        asin reviewerName helpful  unixReviewTime  \\\n",
      "153879  A1PPWRKOYJ6CO5  B006NY4UPS   Vera Green  [0, 0]      1370736000   \n",
      "208779  A2C9QDWHXQIHY0  B007SPPH1M        J3818  [1, 1]      1385856000   \n",
      "\n",
      "                                               reviewText  overall  \\\n",
      "153879  Loved the smell and feel of old London.  Loved...      5.0   \n",
      "208779  This book was ok. I didn't love it, I thought ...      2.0   \n",
      "\n",
      "        reviewTime     summary  sentiments  corrected_sent_score  \n",
      "153879  06 9, 2013  Great read       0.836                 0.336  \n",
      "208779  12 1, 2013          Ok       0.481                 0.000  \n"
     ]
    }
   ],
   "source": [
    "print df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786095, 11)\n",
      "(196524, 11)\n"
     ]
    }
   ],
   "source": [
    "print Training_DataFrame.shape\n",
    "print Testing_DataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset details:\n",
      "Number of item: 61929\n",
      "Number of Users: 68218\n",
      "Number of ratings: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Training dataset details:\"\n",
    "Uniq_items_Train =  len(set(Training_DataFrame['asin'].values))\n",
    "print \"Number of item:\", Uniq_items_Train\n",
    "Uniq_users_Train =   len(set(Training_DataFrame['reviewerID'].values))\n",
    "print \"Number of Users:\", Uniq_users_Train\n",
    "Uniq_ratings_Train = len(set(Training_DataFrame['overall'].values))\n",
    "print \"Number of ratings:\", Uniq_ratings_Train\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training_DataFrame=Training_DataFrame[:5000]\n",
    "Training_DataFrame.columns\n",
    "# Lists of unique items and users\n",
    "item_list = list(set(Training_DataFrame['asin'].values))\n",
    "user_list = list(set(Training_DataFrame['reviewerID'].values))\n",
    "\n",
    "#Storing the indices of users to generate the Rating Memory Matrix\n",
    "UserIndices={}\n",
    "for i in range(len(user_list)):\n",
    "    UserIndices[user_list[i]] = i\n",
    "\n",
    "#Storing the indices of items to generate the Rating Memory Matrix\n",
    "#These indices will be used to populate the UsersRatingMemory for Memory based Collaborative Filtering\n",
    "itemIndices={}\n",
    "for j in range(len(item_list)):\n",
    "    itemIndices[item_list[j]] = j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering without Sentiment Scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings of the Users are:\n",
      "[4.96666667 5.         5.         ... 3.16666667 3.42857143 4.67307692]\n"
     ]
    }
   ],
   "source": [
    "#UsersRatingMemory stores the users and corresponding items ratings in Matrix form\n",
    "UsersRatingMemory=np.zeros((Uniq_users_Train,Uniq_items_Train))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    item_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and item indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    item_ind=itemIndices[item_id]\n",
    "    rating=Training_DataFrame.iloc[i]['overall']\n",
    "    #populate the matrix with rating at corresponding user and item index\n",
    "    UsersRatingMemory[user_ind][item_ind]=float(rating)\n",
    "\n",
    "AvgRatings = np.true_divide(UsersRatingMemory.sum(1),(UsersRatingMemory!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "def PredictUserRating(user_id, item_id):\n",
    "    '''This function predicts the rating based on user_id and item_id'''\n",
    "    item_ind = itemIndices[item_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the item\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory[:,item_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #itemRatingsOthers: stores other users ratings\n",
    "    itemRatingsOthers = UsersRatingMemory[ratedindices, item_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory[ind],UsersRatingMemory[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRatings[user_ind] + k * np.sum( PearsonCoeffs* (itemRatingsOthers - AvgRatings[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Test(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        item_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRating(user_id,item_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'reviewerID', u'asin', u'reviewerName', u'helpful', u'unixReviewTime',\n",
      "       u'reviewText', u'overall', u'reviewTime', u'summary'],\n",
      "      dtype='object')\n",
      "For 10 Samples:\n",
      "The Mean Absolute Error is: 0.5449603142830374\n",
      "Root Mean Square Error is: 0.8166608941062132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Predictions=Test(1000)\n",
    "print \"For 1000 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'].values[:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_other_closest_user(user_ind,k):\n",
    "    PearsonCoeffs={}\n",
    "    for ind in range(len(user_list)):\n",
    "        if ind==user_ind :\n",
    "            continue\n",
    "        else:\n",
    "            PearsonCoeffs[ind]=pearsonr(UsersRatingMemory[ind],UsersRatingMemory[user_ind])[0]\n",
    "        \n",
    "    PearsonCoeffs_sorted=sorted(PearsonCoeffs.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return [x for x, y in PearsonCoeffs_sorted[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-05eb6d847d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolsest_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_other_closest_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#colsest_users_sorted=sorted(colsest_users.items(), key=lambda kv: kv[1], reverse=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#colsest_users=[x for x, y in colsest_users_sorted[:20]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcolsest_users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-527bf9be4972>\u001b[0m in \u001b[0;36mget_other_closest_user\u001b[0;34m(user_ind, k)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mPearsonCoeffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUsersRatingMemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUsersRatingMemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPearsonCoeffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/scipy/stats/stats.pyc\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0mmx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m     \u001b[0mmy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m     \u001b[0mxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3019\u001b[0m     \u001b[0mr_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0mr_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sum_of_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_sum_of_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "colsest_users=get_other_closest_user(0,20)\n",
    "#colsest_users_sorted=sorted(colsest_users.items(), key=lambda kv: kv[1], reverse=True)\n",
    "#colsest_users=[x for x, y in colsest_users_sorted[:20]]\n",
    "print colsest_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommender(user_ind):\n",
    "    items_to_recommend=[]\n",
    "    colsest_users=get_other_closest_user(user_ind,20)\n",
    "    for user in colsest_users:\n",
    "        for items in np.nonzero(UsersRatingMemory[user]):\n",
    "            for item in items:\n",
    "                if UsersRatingMemory[user_ind][item] == 0:\n",
    "                    items_to_recommend.append(item_list[item])\n",
    "    \n",
    "    recommendations = {}\n",
    "    for item in items_to_recommend:\n",
    "        recommendations[item] = PredictUserRating(user_list[user_ind], item)\n",
    "        \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting recommendations for user: AO00I2TVC9LBB\n",
      "Top 10 recommendations are For Collaborative Filtering without sentiment Scores ...\n",
      "[('B00KIXIBYQ', 4.966666666666667), ('B00KBDWHKM', 4.966666666666667), ('B00BTPOFSI', 4.966666666666667), ('B00FR3ZCG2', 4.966666666666667), ('B00GW7NHXM', 4.966666666666667), ('B00IW3BOC0', 4.966666666666667), ('B00KKQACDO', 4.966666666666667), ('B00AMIH8Y6', 4.966666666666667), ('B00L2FQEVG', 4.966666666666667), ('B00CMXCWW2', 4.966666666666667)]\n"
     ]
    }
   ],
   "source": [
    "print \"getting recommendations for user:\", user_list[0]\n",
    "print \"Top 50 recommendations are For Collaborative Filtering without sentiment Scores ...\"\n",
    "recommendations=recommender(0)\n",
    "print recommendations[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colloboarative Filtering with Sentiment Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings of the Users are:\n",
      "[5.29856    5.24056552 4.8829     ... 3.79838    3.97384286 4.69051373]\n"
     ]
    }
   ],
   "source": [
    "UsersRatingMemory_sentiment=np.zeros((Uniq_users_Train,Uniq_items_Train))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    item_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and item indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    item_ind=itemIndices[item_id]\n",
    "    rating=float(Training_DataFrame.iloc[i]['overall'])\n",
    "    \n",
    "    if Training_DataFrame.iloc[i]['reviewText']:\n",
    "    #populate the matrix with rating at corresponding user and item index\n",
    "        rating=rating + float(Training_DataFrame.iloc[i]['corrected_sent_score'])\n",
    "    \n",
    "    UsersRatingMemory_sentiment[user_ind][item_ind]=rating\n",
    "\n",
    "AvgRating_sentiment = np.true_divide(UsersRatingMemory_sentiment.sum(1),(UsersRatingMemory_sentiment!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRating_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def PredictUserRatingsentiment(user_id, item_id):\n",
    "    '''This function predicts the rating based on user_id and item_id'''\n",
    "    item_ind = itemIndices[item_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the item\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory_sentiment[:,item_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #itemRatingsOthers: stores other users ratings\n",
    "    itemRatingsOthers = UsersRatingMemory_sentiment[ratedindices, item_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory_sentiment[ind],UsersRatingMemory_sentiment[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRating_sentiment[user_ind] + k * np.sum( PearsonCoeffs* (itemRatingsOthers - AvgRating_sentiment[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Testsentiment(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        item_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRatingsentiment(user_id,item_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-062f94a448dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTestsentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"For 1000 Samples:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The Mean Absolute Error is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTesting_DataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b25010208284>\u001b[0m in \u001b[0;36mTestsentiment\u001b[0;34m(no_of_samples)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mitem_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTesting_DataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTesting_DataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mPredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPredictUserRatingsentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b25010208284>\u001b[0m in \u001b[0;36mPredictUserRatingsentiment\u001b[0;34m(user_id, item_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mratedindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUsersRatingMemory_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0muser_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Predictions=Testsentiment(1000)\n",
    "print \"For 1000 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'].values[:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_other_closest_user_sentiment(user_ind,k):\n",
    "    PearsonCoeffs={}\n",
    "    for ind in range(len(user_list)):\n",
    "        if ind==user_ind :\n",
    "            continue\n",
    "        else:\n",
    "            PearsonCoeffs[ind]=pearsonr(UsersRatingMemory_sentiment[ind],UsersRatingMemory_sentiment[user_ind])[0]\n",
    "        \n",
    "    PearsonCoeffs_sorted=sorted(PearsonCoeffs.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return [x for x, y in PearsonCoeffs_sorted[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommender_sentiments(user_ind):\n",
    "    items_to_recommend=[]\n",
    "    colsest_users=get_other_closest_user_sentiment(user_ind,20)\n",
    "    for user in colsest_users:\n",
    "        for items in np.nonzero(UsersRatingMemory_sentiment[user]):\n",
    "            for item in items:\n",
    "                if UsersRatingMemory_sentiment[user_ind][item] == 0:\n",
    "                    items_to_recommend.append(item_list[item])\n",
    "    \n",
    "    recommendations = {}\n",
    "    for item in items_to_recommend:\n",
    "        recommendations[item] = PredictUserRatingsentiment(user_list[user_ind], item)\n",
    "        \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting recommendations for user: AO00I2TVC9LBB\n",
      "Top 50 recommendations are For Collaborative Filtering with sentiment Scores ...\n",
      "[('B00KIXIBYQ', 5.240565517241379), ('B00KBDWHKM', 5.240565517241379), ('B00BTPOFSI', 5.240565517241379), ('B00FR3ZCG2', 5.240565517241379), ('B00GW7NHXM', 5.240565517241379), ('B00IW3BOC0', 5.240565517241379), ('B00BVR73P6', 5.240565517241379), ('B00AMIH8Y6', 5.240565517241379), ('B00CMXCWW2', 5.240565517241379), ('B00GM4Y0OU', 5.240565517241379), ('B00KLPFCJI', 5.240565517241379), ('B00FK6WG6K', 5.240565517241379), ('B00HHEVSK8', 5.240565517241379), ('B0058PIWXY', 5.240565517241379), ('B0089MXR6K', 5.240565517241379), ('B004PLNH5K', 5.240565517241379), ('B0069F1LLM', 5.240565517241379), ('B00K0YBVIG', 5.240565517241379), ('B00KXIIZKG', 5.240565517241379), ('B00IZCODEE', 5.240565517241379), ('B008EKOPGS', 5.240565517241379), ('B00F7CJKAC', 5.240565517241379), ('B008OPADK0', 5.240565517241379), ('B00CYBFTWC', 5.240565517241379), ('B00BVA2QBO', 5.240565517241379), ('B00G5ZXKGU', 5.240565517241379), ('B00KZMICVW', 5.240565517241379), ('B00ITTMGZG', 5.240565517241379), ('B00JROS8I6', 5.240565517241379), ('B004XJ4PDW', 5.240565517241379), ('B00D5X6JA4', 5.240565517241379), ('B00LNN4QLW', 5.240565517241379), ('B00I8R7M3U', 5.240565517241379), ('B00AKI4IT6', 5.240565517241379), ('B006F8Q1R2', 5.240565517241379), ('B00ISWZ6O2', 5.240565517241379), ('B00FJGGIF6', 5.240565517241379), ('B00EWN4P9I', 5.240565517241379), ('B004RYVUY0', 5.240565517241379), ('B00HTDVBZ4', 5.240565517241379), ('B009TB004C', 5.240565517241379), ('B00HXR4Y5U', 5.240565517241379), ('B008B0F5QA', 5.240565517241379), ('B00JCJAK96', 5.240565517241379), ('B00GG0OV58', 5.240565517241379), ('B00CIAD6UQ', 5.240565517241379), ('B00J4XQSFK', 5.240565517241379), ('B004R9QVBW', 5.240565517241379), ('B00LXQIL06', 5.240565517241379), ('B00HS5DYDA', 5.240565517241379)]\n"
     ]
    }
   ],
   "source": [
    "print \"getting recommendations for user:\", user_list[1]\n",
    "print \"Top 50 recommendations are For Collaborative Filtering with sentiment Scores ...\"\n",
    "recommendations_sentiment=recommender_sentiments(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
