{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_expected=True\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "if already_expected:\n",
    "    df=pd.read_pickle('../reviews_Kindle_Store_10.h5')\n",
    "    Training_DataFrame = pd.read_pickle('../reviews_Kindle_Store_10_training.h5')\n",
    "    Testing_DataFrame = pd.read_pickle('../reviews_Kindle_Store_10_testing.h5')\n",
    "else:\n",
    "    df = getDF('../reviews_Kindle_Store_10.json.gz')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0fe90f8063b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Training_DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a0a90cd75d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTraining_DataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTesting_DataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Training_DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "print (Training_DataFrame.shape)\n",
    "print (Testing_DataFrame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset details:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Training_DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0450db5f3c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Training dataset details:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mUniq_movies_Train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTraining_DataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of item:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniq_movies_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mUniq_users_Train\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTraining_DataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewerID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of Users:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniq_users_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Training_DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "print (\"Training dataset details:\")\n",
    "Uniq_movies_Train =  len(set(Training_DataFrame['asin'].values))\n",
    "print (\"Number of item:\", Uniq_movies_Train)\n",
    "Uniq_users_Train =   len(set(Training_DataFrame['reviewerID'].values))\n",
    "print (\"Number of Users:\", Uniq_users_Train)\n",
    "Uniq_ratings_Train = len(set(Training_DataFrame['overall'].values))\n",
    "print (\"Number of ratings:\", Uniq_ratings_Train)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472848    5.4167\n",
      "190808    5.4897\n",
      "58803     5.4037\n",
      "80612     5.4495\n",
      "176439    3.0000\n",
      "135231    5.3307\n",
      "432618    5.3201\n",
      "451939    4.4137\n",
      "206509    4.3745\n",
      "96440     4.4676\n",
      "64716     4.2768\n",
      "392679    5.3582\n",
      "407972    5.4038\n",
      "449933    4.0000\n",
      "464025    5.4954\n",
      "342249    5.4743\n",
      "392983    4.3625\n",
      "315399    5.4983\n",
      "166118    3.2635\n",
      "27957     2.0000\n",
      "412140    5.4691\n",
      "358227    5.4641\n",
      "158920    3.4497\n",
      "46870     4.4566\n",
      "127557    3.0000\n",
      "434329    5.0118\n",
      "482760    3.5539\n",
      "240153    5.4891\n",
      "161257    5.2906\n",
      "289913    5.4798\n",
      "           ...  \n",
      "245374    5.3294\n",
      "377128    5.3658\n",
      "283808    5.4868\n",
      "442285    5.4747\n",
      "187781    2.0000\n",
      "169033    4.3906\n",
      "65240     4.3338\n",
      "179587    5.3177\n",
      "171220    3.6010\n",
      "415439    3.4523\n",
      "391035    4.4186\n",
      "412078    5.0000\n",
      "218664    3.3738\n",
      "399374    4.3858\n",
      "182485    5.4926\n",
      "391651    5.4323\n",
      "13325     3.4904\n",
      "158967    4.4552\n",
      "25276     5.4412\n",
      "45169     4.4758\n",
      "42476     5.0000\n",
      "368133    5.0000\n",
      "246191    4.4524\n",
      "134483    5.4916\n",
      "396177    2.2430\n",
      "385126    3.0033\n",
      "409969    5.3949\n",
      "460360    4.0000\n",
      "236913    5.3107\n",
      "358669    5.4501\n",
      "Name: corrected_ratings, Length: 453086, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Training_DataFrame['corrected_ratings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training_DataFrame['corrected_ratings']=[(row['corrected_sent_score'] + row['overall']) for index, row in Training_DataFrame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(Training_DataFrame[['reviewerID', 'asin', 'corrected_ratings']], reader)\n",
    "data_train = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fc86d621860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = Dataset.load_from_df(Testing_DataFrame[['reviewerID', 'asin', 'overall']], reader)\n",
    "testset = data_test.build_full_trainset().build_testset()\n",
    "\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='A2334FRXTW3DN3', iid='B00BCG8KJY', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B008BFXQFM', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B0099U284I', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B00B121R7Q', r_ui=5.0, est=4.773748672564734, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B00CZEBIYG', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B005MYLICS', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B006K5R7Y6', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B00A7Y65HQ', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B0084G2B22', r_ui=5.0, est=5, details={'was_impossible': False}), Prediction(uid='A2334FRXTW3DN3', iid='B00AB77M5S', r_ui=5.0, est=5, details={'was_impossible': False})]\n"
     ]
    }
   ],
   "source": [
    "print( predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7873\n",
      "MAE:  0.4928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49275445573957877"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Recommeder(user, predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid == user:\n",
    "            top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'AO00I2TVC9LBB': [('B00LYPZJ4M', 5),\n",
       "              ('B00EXTVSHI', 5),\n",
       "              ('B00KLERI50', 5),\n",
       "              ('B00KWLI4L4', 5),\n",
       "              ('B00DQ9DVNU', 4.9954299022431092),\n",
       "              ('B00DY8HAMQ', 4.6005826185078078),\n",
       "              ('B00DY8HAL2', 4.5579221484492161)]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommeder(u'AO00I2TVC9LBB', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
