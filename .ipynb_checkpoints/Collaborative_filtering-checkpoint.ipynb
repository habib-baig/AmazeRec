{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_extracted=True\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "if already_extracted:\n",
    "    df = pd.read_pickle('../reviews_Kindle_Store_10_training.h5')\n",
    "    Training_DataFrame = pd.read_pickle('../reviews_Kindle_Store_10_training.h5')\n",
    "    Testing_DataFrame = pd.read_pickle('../reviews_Kindle_Store_10_testing.h5')\n",
    "else:\n",
    "    df = getDF('../reviews_Kindle_Store_5.json.gz')\n",
    "    df = shuffle(df)\n",
    "    Training_DataFrame, Testing_DataFrame = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453086, 13)\n",
      "(50343, 13)\n"
     ]
    }
   ],
   "source": [
    "print Training_DataFrame.shape\n",
    "print Testing_DataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset details:\n",
      "Number of item: 22203\n",
      "Number of Users: 26466\n",
      "Number of ratings: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Dataset details:\"\n",
    "Uniq_items =  len(set(df['asin'].values))\n",
    "print \"Number of item:\", Uniq_items\n",
    "Uniq_users =   len(set(df['reviewerID'].values))\n",
    "print \"Number of Users:\", Uniq_users\n",
    "Uniq_ratings = len(set(df['overall'].values))\n",
    "print \"Number of ratings:\", Uniq_ratings\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training_DataFrame=Training_DataFrame[:5000]\n",
    "Training_DataFrame.columns\n",
    "# Lists of unique items and users\n",
    "item_list = list(set(df['asin'].values))\n",
    "user_list = list(set(df['reviewerID'].values))\n",
    "\n",
    "#Storing the indices of users to generate the Rating Memory Matrix\n",
    "UserIndices={}\n",
    "for i in range(len(user_list)):\n",
    "    UserIndices[user_list[i]] = i\n",
    "\n",
    "#Storing the indices of items to generate the Rating Memory Matrix\n",
    "#These indices will be used to populate the UsersRatingMemory for Memory based Collaborative Filtering\n",
    "itemIndices={}\n",
    "for j in range(len(item_list)):\n",
    "    itemIndices[item_list[j]] = j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering without Sentiment Scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings of the Users are:\n",
      "[4.92307692 5.         3.76923077 ... 3.84615385 3.5        4.64912281]\n"
     ]
    }
   ],
   "source": [
    "#UsersRatingMemory stores the users and corresponding items ratings in Matrix form\n",
    "UsersRatingMemory=np.zeros((Uniq_users,Uniq_items))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    item_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and item indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    item_ind=itemIndices[item_id]\n",
    "    rating=Training_DataFrame.iloc[i]['overall']\n",
    "    #populate the matrix with rating at corresponding user and item index\n",
    "    UsersRatingMemory[user_ind][item_ind]=float(rating)\n",
    "\n",
    "AvgRatings = np.true_divide(UsersRatingMemory.sum(1),(UsersRatingMemory!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "def PredictUserRating(user_id, item_id):\n",
    "    '''This function predicts the rating based on user_id and item_id'''\n",
    "    item_ind = itemIndices[item_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the item\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory[:,item_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #itemRatingsOthers: stores other users ratings\n",
    "    itemRatingsOthers = UsersRatingMemory[ratedindices, item_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory[ind],UsersRatingMemory[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRatings[user_ind] + k * np.sum( PearsonCoeffs* (itemRatingsOthers - AvgRatings[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Test(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        item_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRating(user_id,item_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1000 Samples:\n",
      "The Mean Absolute Error is: 0.5430276579670891\n",
      "Root Mean Square Error is: 0.7988501360441151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Predictions=Test(1000)\n",
    "print \"For 1000 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'].values[:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_other_closest_user(user_ind,k):\n",
    "    PearsonCoeffs={}\n",
    "    for ind in range(len(user_list)):\n",
    "        if ind==user_ind :\n",
    "            continue\n",
    "        else:\n",
    "            PearsonCoeffs[ind]=pearsonr(UsersRatingMemory[ind],UsersRatingMemory[user_ind])[0]\n",
    "        \n",
    "    PearsonCoeffs_sorted=sorted(PearsonCoeffs.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return [x for x, y in PearsonCoeffs_sorted[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommender(user_ind):\n",
    "    items_to_recommend=[]\n",
    "    colsest_users=get_other_closest_user(user_ind,20)\n",
    "    for user in colsest_users:\n",
    "        for items in np.nonzero(UsersRatingMemory[user]):\n",
    "            for item in items:\n",
    "                if UsersRatingMemory[user_ind][item] == 0:\n",
    "                    items_to_recommend.append(item_list[item])\n",
    "    \n",
    "    recommendations = {}\n",
    "    for item in items_to_recommend:\n",
    "        recommendations[item] = PredictUserRating(user_list[user_ind], item)\n",
    "        \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting recommendations for user: AO00I2TVC9LBB\n",
      "Top 10 recommendations are For Collaborative Filtering without sentiment Scores ...\n",
      "[('B00KIXIBYQ', 4.966666666666667), ('B00KBDWHKM', 4.966666666666667), ('B00BTPOFSI', 4.966666666666667), ('B00FR3ZCG2', 4.966666666666667), ('B00GW7NHXM', 4.966666666666667), ('B00IW3BOC0', 4.966666666666667), ('B00KKQACDO', 4.966666666666667), ('B00AMIH8Y6', 4.966666666666667), ('B00L2FQEVG', 4.966666666666667), ('B00CMXCWW2', 4.966666666666667)]\n"
     ]
    }
   ],
   "source": [
    "print \"getting recommendations for user:\", user_list[0]\n",
    "print \"Top 50 recommendations are For Collaborative Filtering without sentiment Scores ...\"\n",
    "recommendations=recommender(0)\n",
    "print recommendations[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colloboarative Filtering with Sentiment Scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratings of the Users are:\n",
      "[5.19210769 5.352625   4.11755385 ... 4.19432308 3.7305625  4.78263509]\n"
     ]
    }
   ],
   "source": [
    "UsersRatingMemory_sentiment=np.zeros((Uniq_users,Uniq_items))\n",
    "\n",
    "for i in range(0, len(Training_DataFrame)):\n",
    "    item_id=Training_DataFrame.iloc[i]['asin']\n",
    "    user_id=Training_DataFrame.iloc[i]['reviewerID']\n",
    "    #get user and item indices\n",
    "    user_ind=UserIndices[user_id]\n",
    "    item_ind=itemIndices[item_id]\n",
    "    rating=float(Training_DataFrame.iloc[i]['overall'])\n",
    "    \n",
    "    if Training_DataFrame.iloc[i]['reviewText']:\n",
    "    #populate the matrix with rating at corresponding user and item index\n",
    "        rating=rating + float(Training_DataFrame.iloc[i]['corrected_sent_score'])\n",
    "    \n",
    "    UsersRatingMemory_sentiment[user_ind][item_ind]=rating\n",
    "\n",
    "AvgRating_sentiment = np.true_divide(UsersRatingMemory_sentiment.sum(1),(UsersRatingMemory_sentiment!=0).sum(1))\n",
    "\n",
    "print \"Average Ratings of the Users are:\"\n",
    "print AvgRating_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def PredictUserRatingsentiment(user_id, item_id):\n",
    "    '''This function predicts the rating based on user_id and item_id'''\n",
    "    item_ind = itemIndices[item_id]\n",
    "    user_ind = UserIndices[user_id]\n",
    "    #ratedindices: it stores the indices of all other users that have rated the item\n",
    "    ratedindices=[]\n",
    "    i=0\n",
    "    for rating in UsersRatingMemory_sentiment[:,item_ind]:\n",
    "        if i==user_ind:\n",
    "            continue\n",
    "        if rating !=0:\n",
    "            ratedindices.append(i)\n",
    "        i+=1\n",
    "    #itemRatingsOthers: stores other users ratings\n",
    "    itemRatingsOthers = UsersRatingMemory_sentiment[ratedindices, item_ind]\n",
    "    #Store the pearson coefficents\n",
    "    PearsonCoeffs=[]\n",
    "    for ind in ratedindices:\n",
    "        PearsonCoeffs.append(pearsonr(UsersRatingMemory_sentiment[ind],UsersRatingMemory_sentiment[user_ind])[0])\n",
    "    k=0.001\n",
    "    # Calculate the prediction\n",
    "    pred = AvgRating_sentiment[user_ind] + k * np.sum( PearsonCoeffs* (itemRatingsOthers - AvgRating_sentiment[ratedindices]))\n",
    "    return pred\n",
    "\n",
    "def Testsentiment(no_of_samples):\n",
    "    '''This function returns the predictions for given no of samples'''\n",
    "    Predictions=np.zeros(no_of_samples)\n",
    "    for i in range(no_of_samples):\n",
    "        item_id=Testing_DataFrame.iloc[i]['asin']\n",
    "        user_id=Testing_DataFrame.iloc[i]['reviewerID']\n",
    "        Predictions[i]=PredictUserRatingsentiment(user_id,item_id)\n",
    "    return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1000 Samples:\n",
      "The Mean Absolute Error is: 0.5915488267025667\n",
      "Root Mean Square Error is: 0.8618822029935236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "Predictions=Testsentiment(1000)\n",
    "print \"For 1000 Samples:\"\n",
    "print \"The Mean Absolute Error is:\", mean_absolute_error(Predictions, Testing_DataFrame['overall'].values[:1000])\n",
    "print \"Root Mean Square Error is:\", np.sqrt(mean_squared_error(Predictions, Testing_DataFrame['overall'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_other_closest_user_sentiment(user_ind,k):\n",
    "    PearsonCoeffs={}\n",
    "    for ind in range(len(user_list)):\n",
    "        if ind==user_ind :\n",
    "            continue\n",
    "        else:\n",
    "            PearsonCoeffs[ind]=pearsonr(UsersRatingMemory_sentiment[ind],UsersRatingMemory_sentiment[user_ind])[0]\n",
    "        \n",
    "    PearsonCoeffs_sorted=sorted(PearsonCoeffs.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return [x for x, y in PearsonCoeffs_sorted[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommender_sentiments(user_ind):\n",
    "    items_to_recommend=[]\n",
    "    colsest_users=get_other_closest_user_sentiment(user_ind,20)\n",
    "    for user in colsest_users:\n",
    "        for items in np.nonzero(UsersRatingMemory_sentiment[user]):\n",
    "            for item in items:\n",
    "                if UsersRatingMemory_sentiment[user_ind][item] == 0:\n",
    "                    items_to_recommend.append(item_list[item])\n",
    "    \n",
    "    recommendations = {}\n",
    "    for item in items_to_recommend:\n",
    "        recommendations[item] = PredictUserRatingsentiment(user_list[user_ind], item)\n",
    "        \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting recommendations for user: AO00I2TVC9LBB\n",
      "Top 50 recommendations are For Collaborative Filtering with sentiment Scores ...\n"
     ]
    }
   ],
   "source": [
    "print \"getting recommendations for user:\", user_list[0]\n",
    "print \"Top 50 recommendations are For Collaborative Filtering with sentiment Scores ...\"\n",
    "recommendations_sentiment=recommender_sentiments(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B00GO6VI50', 5.192107692307692), ('B00B3KPBSW', 5.192107692307692), ('B009P59SFY', 5.192107692307692), ('B00HLX9Z3C', 5.192107692307692), ('B00JHNAWQS', 5.192107692307692), ('B00KA0AGJK', 5.192107692307692), ('B00GW9H8XA', 5.192107692307692), ('B002HUU0A6', 5.192107692307692), ('B0091V9BPE', 5.192107692307692), ('B00KXIIZKG', 5.192107692307692), ('B00L7DRQME', 5.192107692307692), ('B002FK3U00', 5.192107692307692), ('B00KF0URBM', 5.192107692307692), ('B00KKQACDO', 5.192107692307692), ('B008EXK208', 5.192107692307692), ('B00KBA6PKS', 5.192107692307692), ('B00BN1E6SW', 5.192107692307692), ('B00EUSSY3S', 5.192107692307692), ('B00EZ8PNK0', 5.192107692307692), ('B00CMXCWW2', 5.192107692307692), ('B000R93D4Y', 5.192107692307692), ('B00KY7X0OC', 5.192107692307692), ('B00CI95PS8', 5.192107692307692), ('B00GKKU0OK', 5.192107692307692), ('B00JWET7TU', 5.192107692307692), ('B00GMSI5BA', 5.192107692307692), ('B0064EIC9C', 5.192107692307692), ('B005NKEEYK', 5.192107692307692), ('B00HBY8SIY', 5.192107692307692), ('B00LS3MXVW', 5.192107692307692), ('B00AKKN9Z8', 5.192107692307692), ('B00HBY2SSU', 5.192107692307692), ('B00FAH38DE', 5.192107692307692), ('B0088NH1K8', 5.192107692307692), ('B0088PB5CG', 5.192107692307692), ('B00DJB6KE2', 5.192107692307692), ('B00AYIDVLS', 5.192107692307692), ('B00JVAPRVW', 5.192107692307692), ('B0082GVXSM', 5.192107692307692), ('B007QUU9JO', 5.192107692307692), ('B005NI5XUG', 5.192107692307692), ('B00KJ7RAYI', 5.192107692307692), ('B00GXLDT9O', 5.192107692307692), ('B0080GUO6Q', 5.192107692307692), ('B007YN8IGE', 5.192107692307692), ('B00HTP1P26', 5.192107692307692), ('B00F3OO3IS', 5.192107692307692), ('B00H95FQRG', 5.192107692307692), ('B00D89OGB4', 5.192107692307692), ('B00JA26TTU', 5.192107692307692)]\n"
     ]
    }
   ],
   "source": [
    "print recommendations_sentiment[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
